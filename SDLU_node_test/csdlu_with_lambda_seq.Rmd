---
title: "single layer fit using residuals"
author: "SDMLAB"
date: \today
fontsize: 12pt
output:
   pdf_document:
     includes:
       in_header: GoodMarkdown.tex
     number_sections: yes
editor_options: 
  chunk_output_type: console
---

# data generations
```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.align='center', fig.width=5, fig.height=5}
rm(list = ls())
source("lib_SDLU.R")
source("csdlu_v2.R")
set.seed(5)
n = 800
x = sort(runif(n, 0, 1))
f = 2*x + sin((7*x)^2)
y = f + rnorm(n) * 0.2
par(mfrow = c(1, 1))
plot(x, y, col = "grey")
lines(x, f, col = "black")
```


# first fit using $10$ nodes with large support
```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.align='center', fig.width=7, fig.height=4}
number_lambdas = 100
number_group = 5
number_nodes = c(4, 8, 16, 32, 64)
#number_nodes = c(25, 25, 25, 25, 25)
width = matrix(0, number_group, 2)
range = max(x) - min(x)
beta = alpha0 = alpha1 =c()
set.seed(10)
for (j in 1 : number_group)
{
   width[j, ] = c(range, 2 * range) / (2^(j - 1))
   widths = runif(number_nodes[j], width[j, 1], width[j, 2])
   initial_values = initial_values_SDLU(x, number_nodes[j], widths)
   beta = c(beta, initial_values$beta)
   alpha1 = c(alpha1, initial_values$alpha1)
   alpha0 = c(alpha0, initial_values$alpha0)
}

fit1 = csdlu_v2(response = y, predictor = cbind(x),
                number_nodes = number_nodes, number_group = number_group,
                lambda_max = 0.2, lambda_max_min_ratio = 1e-07,
                number_lambdas = number_lambdas, max_iteration = 1000,
                initial_bias = rep(0, number_group), 
                initial_beta = beta, initial_alpha0 = alpha0,
                initial_alpha1 = alpha1, verbose = T, iter_epsilon = 1e-04)
```


## activated planes and fitted function
```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.align='center', fig.width=7, fig.height=3.5}
index = which.min(fit1$bic_list)
final_nodes = length(fit1[[index]]$beta[fit1[[index]]$beta != 0])
par(mfrow = c(1, 2), pty = "s")
matplot(x, fit1[[index]]$active_planes, type = "l", lty = 1, main = 'Final activation function', ylab = " ")
plot(x, y, col = "grey", main = paste('Final fit (nodes: ', final_nodes,')'))
lines(x, fit1[[index]]$fitted_values, col = "red", lwd = 2)
```

# test
```{r}
index_list = 1:70
for (index in index_list)
{
   final_nodes = length(fit1[[index]]$beta[fit1[[index]]$beta != 0])
   par(mfrow = c(1, 2), pty = "s")
   matplot(x, fit1[[index]]$active_planes, type = "l", lty = 1, main = paste('Lambda index: ',index), ylab = " ")
   plot(x, y, col = "grey", main = paste('Final fit (nodes: ', final_nodes,')'))
   lines(x, fit1[[index]]$fitted_values, col = "red", lwd = 2)
}
```


# activated planes of each resoultion
```{r}
par(mfrow = c(1, 2))
active_planes = matrix(0, n, sum(number_nodes))
for (j in 1 : sum(number_nodes))
{
   active_planes[, j] = fit1[[index]]$beta[j] * fit1[[index]]$active_planes[, j]
}

residual = y

for (j in 1 : fit1$number_group)
{
   indices = fit1$group_index[j, 1] : fit1$group_index[j, 2]
   resid_fit = rowSums(active_planes[, indices])
   matplot(x, active_planes[, indices], 
           type = "l", lty = 1, ylab = "", 
           main = paste('Group', j, 'Activaion function'))
   
   plot(x, scale(residual, scale = F), col = 'grey', 
        main = paste('Group', j, 'Resolution'), ylab = "")
   lines(x, scale(resid_fit, scale = F), col = 'red', lwd = 2)
   residual = residual - rowSums(active_planes[, indices])
}
```



